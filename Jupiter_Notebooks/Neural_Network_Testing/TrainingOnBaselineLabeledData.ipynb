{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:37:51.988100Z",
     "start_time": "2024-06-07T15:37:51.984174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ],
   "id": "d999aa993d3b38ed",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-07T15:37:53.677142Z",
     "start_time": "2024-06-07T15:37:53.038290Z"
    }
   },
   "source": [
    "file_path = '../../Data/Verified/BaseLineLabeledWithoutSelfLabeledValues/'\n",
    "file_name = 'RecordedDrivingData.csv'\n",
    "\n",
    "recorded_driving_dataframe = pd.read_csv(file_path + file_name)\n",
    "\n",
    "recorded_driving_dataframe['Timestamp'] = pd.to_datetime(recorded_driving_dataframe['Timestamp'])\n",
    "\n",
    "primary_data = recorded_driving_dataframe[['Lateral acceleration','Longitudinal acceleration']]\n",
    "full_data = recorded_driving_dataframe\n",
    "data_labels = recorded_driving_dataframe['Label']\n",
    "data_labels = data_labels.loc[primary_data.index]"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T15:39:27.154650Z",
     "start_time": "2024-06-07T15:39:21.991402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(data_labels)\n",
    "\n",
    "Train_Data, Test_Data, Train_Labels, Test_Labels = train_test_split(primary_data, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(Train_Data.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "color_map_for_plot = {\n",
    "    'Excellent': 'green',\n",
    "    'Acceptable': 'yellow',\n",
    "    'So and So': 'orange',\n",
    "    'Uncomfortable': 'red',\n",
    "}\n",
    "\n",
    "class ActivationLogger(Callback):\n",
    "    def __init__(self, layer_index):\n",
    "        super(ActivationLogger, self).__init__()\n",
    "        self.layer_index = layer_index\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        layer_output_model = tf.keras.Model(inputs=self.model.input,\n",
    "                                            outputs=self.model.layers[self.layer_index].output)\n",
    "        activations = layer_output_model.predict(self.model.input)\n",
    "        zero_activations = np.sum(activations == 0)\n",
    "        total_activations = activations.size\n",
    "        zero_fraction = zero_activations / total_activations\n",
    "        print(f'Epoch {epoch+1}: Layer {self.layer_index} - Zero activations: {zero_fraction * 100:.2f}%')\n",
    "\n",
    "\n",
    "class PredictionCallback(Callback):\n",
    "    def __init__(self, Test_Data, Test_Labels, label_encoder, dataframe, color_map):\n",
    "        self.Test_Data = Test_Data\n",
    "        self.Test_Labels = Test_Labels\n",
    "        self.label_encoder = label_encoder\n",
    "        self.dataframe = dataframe\n",
    "        self.color_map = color_map\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 50 == 0:\n",
    "            test_data_predictions = self.model.predict(self.Test_Data)\n",
    "            test_labels_predictions = np.argmax(test_data_predictions, axis=1)\n",
    "            true_labels = self.Test_Labels\n",
    "\n",
    "            accuracy_per_epoch = np.mean(test_labels_predictions == true_labels)\n",
    "            loss_per_epoch = logs['val_loss']\n",
    "            print(f'Epoch: {epoch + 1}')\n",
    "            print(f'Accuracy: {accuracy_per_epoch}')\n",
    "            print(f'Loss: {loss_per_epoch}')\n",
    "\n",
    "            test_labels_predictions_mapped = self.label_encoder.inverse_transform(test_labels_predictions)\n",
    "\n",
    "            fig, axis = plt.subplots()\n",
    "            fig.set_size_inches(4, 4)\n",
    "\n",
    "            plot_dataframe = pd.DataFrame({\n",
    "                'Lateral acceleration': self.Test_Data[:, 0],\n",
    "                'Longitudinal acceleration': self.Test_Data[:, 1],\n",
    "                'Label': test_labels_predictions_mapped\n",
    "            })\n",
    "\n",
    "            colors = plot_dataframe['Label'].map(self.color_map)\n",
    "\n",
    "            axis.scatter(plot_dataframe['Lateral acceleration'], plot_dataframe['Longitudinal acceleration'], c=colors)\n",
    "\n",
    "            max_lateral = plot_dataframe['Lateral acceleration'].max()\n",
    "            max_longitudinal = plot_dataframe['Longitudinal acceleration'].max()\n",
    "            maximum_axis_value = max(max_lateral, max_longitudinal)\n",
    "\n",
    "            axis.set_xlim(-maximum_axis_value - 0.5, maximum_axis_value + 0.5)\n",
    "            axis.set_ylim(-maximum_axis_value - 0.5, maximum_axis_value + 0.5)\n",
    "\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Lateral acceleration')\n",
    "            plt.ylabel('Longitudinal acceleration')\n",
    "            plt.title(f'Predicted Labels By Model After {epoch + 1} Epochs')\n",
    "            plt.show()\n",
    "\n",
    "# Combine both callbacks\n",
    "callbacks = [\n",
    "    ActivationLogger(layer_index=1),\n",
    "    PredictionCallback(Test_Data, Test_Labels, label_encoder, primary_data, color_map_for_plot)\n",
    "]\n",
    "\n",
    "# Train the model with both callbacks\n",
    "model_history = model.fit(Train_Data, Train_Labels, epochs=20, batch_size=32, validation_split=0.2, callbacks=callbacks)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(Test_Data, Test_Labels)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "id": "32a86dee4eedcfe6",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:38:18.656891Z",
     "start_time": "2024-06-02T15:38:18.651081Z"
    }
   },
   "cell_type": "code",
   "source": "print(Test_Data)",
   "id": "4164c6731260f9b6",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:10.661021Z",
     "start_time": "2024-06-02T15:33:08.154064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make predictions on the test data\n",
    "test_data_predictions = model.predict(Test_Data)\n",
    "test_labels_predictions = np.argmax(test_data_predictions, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(Test_Data, Test_Labels)\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(Test_Labels, test_labels_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Assuming Test_Labels and test_labels_predictions are already defined\n",
    "\n",
    "# Get precision, recall, and f1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(Test_Labels, test_labels_predictions, average=None)\n",
    "\n",
    "specificity = []\n",
    "for i in range(len(cm)):\n",
    "    tn = np.sum(cm) - (np.sum(cm[:, i]) + np.sum(cm[i, :]) - cm[i, i])\n",
    "    fp = np.sum(cm[:, i]) - cm[i, i]\n",
    "    specificity.append(tn / (tn + fp))\n",
    "\n",
    "# Create a DataFrame for the scores\n",
    "labels = label_encoder.inverse_transform([0, 1, 2, 3])\n",
    "scores_df = pd.DataFrame({\n",
    "    'Label': labels,\n",
    "    'Precision (%)': precision * 100,\n",
    "    'Recall (%)': recall * 100,\n",
    "    'F1-Score (%)': f1 * 100,\n",
    "    'Specificity (%)': np.array(specificity) * 100\n",
    "})\n",
    "\n",
    "# Create a DataFrame for the scores\n",
    "labels = label_encoder.inverse_transform([0, 1, 2, 3])\n",
    "scores_df = pd.DataFrame({\n",
    "    'Label': labels,\n",
    "    'Precision (%)': (precision * 100).round(2),\n",
    "    'Recall (%)': (recall * 100).round(2),\n",
    "    'F1-Score (%)': (f1 * 100).round(2),\n",
    "    'Specificity (%)': (np.array(specificity) * 100).round(2)\n",
    "})\n",
    "\n",
    "# Plotting the table\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "ax.table(cellText=scores_df.values, colLabels=scores_df.columns, cellLoc='center', loc='center', bbox=[0, 0, 1, 1])\n",
    "\n",
    "plt.title('Classification Report', pad=20)\n",
    "plt.show()"
   ],
   "id": "fd2b59812da0d179",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:10.664630Z",
     "start_time": "2024-06-02T15:33:10.661021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model_json_config = model.to_json()\n",
    "# \n",
    "# directory = '../../AIModels/BaselineModel/Epochs/'\n",
    "# os.makedirs(directory, exist_ok=True)\n",
    "# \n",
    "# with open(directory + 'DrivingComfortabilityPredictingModel.json', 'w') as json_file:\n",
    "#     json_file.write(model_json_config)\n",
    "#     \n",
    "# model.save_weights(directory +  'DrivingComfortabilityPredictingModel.weights.h5')\n",
    "# \n",
    "# with open(directory + 'DrivingComfortabilityPredictingModelHistory.pkl', 'wb') as f:\n",
    "#     pickle.dump(model_history.history, f)"
   ],
   "id": "a220d209e9f3fce6",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:10.684101Z",
     "start_time": "2024-06-02T15:33:10.665631Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('../../AIModels/BaselineModel/20Epochs/FullModel/DrivingComfortabilityPredictingModel.keras')",
   "id": "8a6794366074e96e",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T15:33:10.687133Z",
     "start_time": "2024-06-02T15:33:10.685101Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5c6e665ad1565b10",
   "execution_count": 33,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
